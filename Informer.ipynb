{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e915fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/zhouhaoyi/Informer2020.git\n",
    "# !git clone https://github.com/zhouhaoyi/ETDataset.git\n",
    "\n",
    "# pip install numpy==1.* torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "\n",
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880b6086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu128\n",
      "torch.cuda.is_available: True\n",
      "torch.version.cuda: 12.8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if not 'Informer2020' in sys.path:\n",
    "    sys.path += ['Informer2020']\n",
    "\n",
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(f\"torch.cuda.is_available: {torch.cuda.is_available()}\")\n",
    "print(f\"torch.version.cuda: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eaff333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use: True\n"
     ]
    }
   ],
   "source": [
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "args.data = 'ETTm1' # data our data: NIFTY100_1m test data: ETTm1\n",
    "args.root_path = './ETDataset/ETT-small/' # root path of data file\n",
    "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.freq = 't' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 180 # input sequence length of Informer encoder\n",
    "args.label_len = 48 # start token length of Informer decoder\n",
    "args.pred_len = 5 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.factor = 10 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 4 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 1024 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = True # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "\n",
    "args.batch_size = 400 \n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.train_epochs = 30\n",
    "args.patience = 3\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'\n",
    "\n",
    "print(f\"GPU in use: {args.use_gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1b4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set augments by using data name\n",
    "data_parser = {\n",
    "    'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "    'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
    "\t'NIFTY100_1m':{'data':'NIFTY100_1m.csv','T':'close','MS':[7,7,1], 'M':[6,6,6]},\n",
    "\t'GAZP_combo':{'data':'GAZP_combo.csv','T':'gazp','MS':[6,6,1], 'M':[6,6,6]},\n",
    " \t'GAZP_combo_2':{'data':'GAZP_combo_2.csv','T':'gazp','MS':[6,6,1], 'M':[6,6,6]},\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "    data_info = data_parser[args.data]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T'] # target feature in S or MS task\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]\n",
    "   \n",
    "\t # args.enc_in - encoder input size\n",
    "\t # args.dec_in - decoder input size\n",
    "\t # args.c_out - output size\n",
    "else:\n",
    "   raise ValueError(f\"No {args.data} in data_parser.keys()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6be7d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e29c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_ETTm1_ftM_sl180_ll48_pl5_dm512_nh4_el2_dl1_df1024_atprob_fc10_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "train 55560\n",
      "\n",
      "val 6964\n",
      "\n",
      "test 6964\n",
      "\titers: 100, epoch: 1 | loss: 0.1153699\n",
      "\tspeed: 0.3425s/iter; left time: 1384.0073s\n",
      "Epoch: 1 cost time: 45.939656496047974\n",
      "Epoch: 1, Steps: 138 | Train Loss: 0.2081040 Vali Loss: 0.1303649 Test Loss: 0.1473155\n",
      "Validation loss decreased (inf --> 0.130365).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0795015\n",
      "\tspeed: 0.6156s/iter; left time: 2402.7018s\n",
      "Epoch: 2 cost time: 44.66612100601196\n",
      "Epoch: 2, Steps: 138 | Train Loss: 0.0901085 Vali Loss: 0.1123780 Test Loss: 0.1346495\n",
      "Validation loss decreased (0.130365 --> 0.112378).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0762265\n",
      "\tspeed: 0.6348s/iter; left time: 2390.1109s\n",
      "Epoch: 3 cost time: 48.05846285820007\n",
      "Epoch: 3, Steps: 138 | Train Loss: 0.0809722 Vali Loss: 0.1075111 Test Loss: 0.1360760\n",
      "Validation loss decreased (0.112378 --> 0.107511).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0737151\n",
      "\tspeed: 0.6642s/iter; left time: 2409.1183s\n",
      "Epoch: 4 cost time: 46.61375331878662\n",
      "Epoch: 4, Steps: 138 | Train Loss: 0.0777055 Vali Loss: 0.1030920 Test Loss: 0.1303119\n",
      "Validation loss decreased (0.107511 --> 0.103092).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0670640\n",
      "\tspeed: 0.6266s/iter; left time: 2186.3717s\n",
      "Epoch: 5 cost time: 45.28339910507202\n",
      "Epoch: 5, Steps: 138 | Train Loss: 0.0757942 Vali Loss: 0.1026038 Test Loss: 0.1296966\n",
      "Validation loss decreased (0.103092 --> 0.102604).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0727063\n",
      "\tspeed: 0.5908s/iter; left time: 1979.8533s\n",
      "Epoch: 6 cost time: 43.354656457901\n",
      "Epoch: 6, Steps: 138 | Train Loss: 0.0748194 Vali Loss: 0.1014911 Test Loss: 0.1308859\n",
      "Validation loss decreased (0.102604 --> 0.101491).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0819305\n",
      "\tspeed: 0.5679s/iter; left time: 1824.7576s\n",
      "Epoch: 7 cost time: 40.401098012924194\n",
      "Epoch: 7, Steps: 138 | Train Loss: 0.0743945 Vali Loss: 0.1003164 Test Loss: 0.1296018\n",
      "Validation loss decreased (0.101491 --> 0.100316).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0735641\n",
      "\tspeed: 0.5410s/iter; left time: 1663.6915s\n",
      "Epoch: 8 cost time: 40.45300817489624\n",
      "Epoch: 8, Steps: 138 | Train Loss: 0.0740882 Vali Loss: 0.1014598 Test Loss: 0.1299608\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0748672\n",
      "\tspeed: 0.5376s/iter; left time: 1578.8808s\n",
      "Epoch: 9 cost time: 40.12571406364441\n",
      "Epoch: 9, Steps: 138 | Train Loss: 0.0738888 Vali Loss: 0.1012756 Test Loss: 0.1290298\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0671124\n",
      "\tspeed: 0.5404s/iter; left time: 1512.5445s\n",
      "Epoch: 10 cost time: 40.38561296463013\n",
      "Epoch: 10, Steps: 138 | Train Loss: 0.0738222 Vali Loss: 0.1016545 Test Loss: 0.1299888\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_ETTm1_ftM_sl180_ll48_pl5_dm512_nh4_el2_dl1_df1024_atprob_fc10_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\n",
      "test 6964\n",
      "test shape: (17, 400, 5, 7) (17, 400, 5, 7)\n",
      "test shape: (6800, 5, 7) (6800, 5, 7)\n",
      "mse:0.12956450879573822, mae:0.22703395783901215\n"
     ]
    }
   ],
   "source": [
    "# setting record of experiments\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ii = 0\n",
    "setting = f'{args.model}_{args.data}_ft{args.features}_sl{args.seq_len}_ll{args.label_len}\\\n",
    "_pl{args.pred_len}_dm{args.d_model}_nh{args.n_heads}_el{args.e_layers}_dl{args.d_layers}_df{args.d_ff}\\\n",
    "_at{args.attn}_fc{args.factor}_eb{args.embed}_dt{args.distil}_mx{args.mix}_{args.des}_{ii}'\n",
    "\n",
    "# set experiments\n",
    "exp = Exp_Informer(args)\n",
    "\n",
    "# train\n",
    "print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "exp.train(setting)\n",
    "\n",
    "# test\n",
    "print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "exp.test(setting)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a02555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "pred 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[14.34109736,  4.11343317,  9.62179671,  1.93871046,\n",
       "          4.66827986,  1.44486514,  8.78766807],\n",
       "        [14.39241874,  4.06452512,  9.48739623,  1.96010379,\n",
       "          4.5791833 ,  1.43437699,  8.28596629],\n",
       "        [14.42261884,  4.1347334 ,  9.68108617,  1.97527742,\n",
       "          4.65006038,  1.43875528,  8.52632974],\n",
       "        [14.51175294,  4.05762681,  9.58978683,  1.93271255,\n",
       "          4.66752982,  1.42588657,  8.42428758],\n",
       "        [14.43198136,  4.0985133 ,  9.5598187 ,  2.00983661,\n",
       "          4.53544439,  1.42060802,  8.17950219]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ext = Exp_Informer(args)\n",
    "path = os.path.join(ext.args.checkpoints, setting)\n",
    "best_model_path = path+'/'+'checkpoint.pth'\n",
    "ext.model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "pred_data, pred_loader = exp._get_data(flag='pred')\n",
    "\n",
    "exp.model.eval()\n",
    "\n",
    "preds = []\n",
    "\n",
    "for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n",
    "\tpred, true = exp._process_one_batch(\n",
    "\t\t\tpred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "\tpreds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "preds = np.array(preds)\n",
    "preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "\n",
    "pred_data.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb49c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13300876"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.vali(pred_data, pred_loader, exp._select_criterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34ffdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.45800018,  5.4920001 ,  9.70100021, ...,  2.16300011,\n",
       "         0.88300002,  8.51200008],\n",
       "       [14.33399963,  5.69299984,  9.91399956, ...,  4.5079999 ,\n",
       "         1.24899995,  8.58199978],\n",
       "       [14.53499985,  5.55900002,  9.80799961, ...,  4.47700024,\n",
       "         1.24899995,  8.72299957],\n",
       "       ...,\n",
       "       [10.7840004 ,  3.34899998,  7.        , ...,  3.74600005,\n",
       "         1.43200004,  9.42599964],\n",
       "       [11.65499973,  3.6170001 ,  7.53299999, ...,  4.17299986,\n",
       "         1.523     ,  9.42599964],\n",
       "       [12.99400043,  3.81800008,  8.24400043, ...,  4.72100019,\n",
       "         1.523     ,  9.77799988]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data.inverse_transform(pred_data.data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81251578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99820ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legacy_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
